<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <meta name="author" content="Mrinal(Ishant) Haloi">
  <link rel="shortcut icon" href="../../img/favicon.ico">
  <title>Utils - Tefla</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Utils";
    var mkdocs_page_input_path = "utils/util.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../../js/jquery-2.1.1.min.js" defer></script>
  <script src="../../js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href="../.." class="icon icon-home"> Tefla</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="../..">Home</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../..">Index</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../installation/">Installation</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Layers</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../core/layers/">Layers</a>
                </li>
                <li class="">
                    
    <a class="" href="../../core/rnn_cell/">RNN</a>
                </li>
                <li class="">
                    
    <a class="" href="../../core/special_layers/">Special Layers</a>
                </li>
                <li class="">
                    
    <a class="" href="../../core/layer_arg_ops/">Layer Args</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Learner</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../core/training/">Learner</a>
                </li>
                <li class="">
                    
    <a class="" href="../../core/learning/">Learner Multi GPU</a>
                </li>
                <li class="">
                    
    <a class="" href="../../core/learning_v2/">Learner Multi GPU V2</a>
                </li>
                <li class="">
                    
    <a class="" href="../../core/learning_ss/">Learner Semi Supervised</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Predictor</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../core/prediction/">Predictor</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Built-in Ops</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../core/lr_policy/">Lr_Policy</a>
                </li>
                <li class="">
                    
    <a class="" href="../../core/metrics/">Metrics</a>
                </li>
                <li class="">
                    
    <a class="" href="../../core/initializers/">Initializations</a>
                </li>
                <li class="">
                    
    <a class="" href="../../core/losses/">Losses</a>
                </li>
                <li class="">
                    
    <a class="" href="../../core/summary/">Summaries</a>
                </li>
                <li class="">
                    
    <a class="" href="../../core/logger/">Logger</a>
                </li>
                <li class="">
                    
    <a class="" href="../../core/iter_ops/">Iter Ops</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Data Management</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../da/data/">Data Augmentation</a>
                </li>
                <li class="">
                    
    <a class="" href="../../da/standardizer/">Standardizer</a>
                </li>
                <li class="">
                    
    <a class="" href="../../dataset/image_to_tfrecords/">TfRecords</a>
                </li>
                <li class="">
                    
    <a class="" href="../../dataset/base/">Dataset</a>
                </li>
                <li class="">
                    
    <a class="" href="../../dataset/dataflow/">Dataflow</a>
                </li>
                <li class="">
                    
    <a class="" href="../../dataset/decoder/">Decoder</a>
                </li>
                <li class="">
                    
    <a class="" href="../../dataset/reader/">Reader</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Utils</span>
    <ul class="subnav">
                <li class=" current">
                    
    <a class="current" href="./">Utils</a>
    <ul class="subnav">
            
    <li class="toctree-l3"><a href="#device-chooser-for-variables">Device chooser for variables</a></li>
    

    <li class="toctree-l3"><a href="#valid-types-for-loss-variables-and-gradients">Valid types for loss, variables and gradients</a></li>
    

    <li class="toctree-l3"><a href="#asserts-tensors-are-all-valid-types-see-_valid_dtypes">Asserts tensors are all valid types (see _valid_dtypes)</a></li>
    

    <li class="toctree-l3"><a href="#returns-value-if-value_or_tensor_or_var-has-a-constant-value">Returns value if value_or_tensor_or_var has a constant value</a></li>
    

    <li class="toctree-l3"><a href="#return-either-fn1-or-fn2-based-on-the-boolean-value-of-pred">Return either fn1() or fn2() based on the boolean value of pred</a></li>
    

    <li class="toctree-l3"><a href="#return-either-fn1-or-fn2-based-on-the-boolean-predicatevalue-pred">Return either fn1() or fn2() based on the boolean predicate/value pred</a></li>
    

    <li class="toctree-l3"><a href="#transform-numeric-labels-into-onehot_labels">Transform numeric labels into onehot_labels</a></li>
    

    <li class="toctree-l3"><a href="#returns-a-true-if-its-input-is-a-collectionssequence-except-strings">Returns a true if its input is a collections.Sequence (except strings)</a></li>
    

    <li class="toctree-l3"><a href="#returns-a-flat-sequence-from-a-given-nested-structure">Returns a flat sequence from a given nested structure</a></li>
    

    <li class="toctree-l3"><a href="#returns-the-last-dimension-of-shape-while-checking-it-has-min_rank">Returns the last dimension of shape while checking it has min_rank</a></li>
    

    <li class="toctree-l3"><a href="#load-graph-from-frozen-weights-and-model">Load Graph from frozen weights and model</a></li>
    

    <li class="toctree-l3"><a href="#normalize-a-input-layer">Normalize a input layer</a></li>
    

    <li class="toctree-l3"><a href="#denormalize-a-input-layer">DeNormalize a input layer</a></li>
    

    <li class="toctree-l3"><a href="#computes-the-squared-pairwise-euclidean-distances-between-x-and-y">Computes the squared pairwise Euclidean distances between x and y</a></li>
    

    <li class="toctree-l3"><a href="#computes-a-guassian-radial-basis-kernel-between-the-samples-of-x-and-y">Computes a Guassian Radial Basis Kernel between the samples of x and y</a></li>
    

    <li class="toctree-l3"><a href="#compute-the-length-of-a-sequence-0-are-masked">compute the length of a sequence. 0 are masked</a></li>
    

    <li class="toctree-l3"><a href="#advanced-indexing-for-sequences">Advanced Indexing for Sequences</a></li>
    

    <li class="toctree-l3"><a href="#pad_sequences">pad_sequences</a></li>
    

    <li class="toctree-l3"><a href="#creates-a-dictionary-charinteger-for-each-unique-character">Creates a dictionary char:integer for each unique character</a></li>
    

    <li class="toctree-l3"><a href="#string_to_semi_redundant_sequences">string_to_semi_redundant_sequences</a></li>
    

    <li class="toctree-l3"><a href="#vectorize-text-file">Vectorize Text file</a></li>
    

    <li class="toctree-l3"><a href="#computes-log-probabilities-using-numerically-stable-trick">Computes log probabilities using numerically stable trick</a></li>
    

    <li class="toctree-l3"><a href="#get-the-name-of-the-op-that-created-a-tensor">Get the name of the op that created a tensor</a></li>
    

    <li class="toctree-l3"><a href="#returns-the-union-of-two-lists">Returns the union of two lists</a></li>
    

    <li class="toctree-l3"><a href="#maps-xs-to-consumers">Maps xs to consumers</a></li>
    

    <li class="toctree-l3"><a href="#clip-an-array-of-tensors-by-l2-norm">Clip an array of tensors by L2 norm</a></li>
    

    <li class="toctree-l3"><a href="#add-iid-gaussian-noise-0-sigma2-to-every-entry-of-t">Add i.i.d. Gaussian noise (0, sigma^2) to every entry of t</a></li>
    

    </ul>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../license/">License</a>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../..">Tefla</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../..">Docs</a> &raquo;</li>
    
      
        
          <li>Utils &raquo;</li>
        
      
    
    <li>Utils</li>
    <li class="wy-breadcrumbs-aside">
      
        <a href="https://github.com/n3011/tefla/edit/master/docs/utils/util.md"
          class="icon icon-github"> Edit on GitHub</a>
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="device-chooser-for-variables">Device chooser for variables</h1>
<p><span class="extra_h1"><span style="color:black;"><a href=https://github.com/n3011/tefla/blob/master/tefla/utils/util.py#L391 target="_blank"><b>tefla.utils.util.VariableDeviceChooser</b></a></span>  (num_parameter_servers=0,  ps_device='/job:ps',  placement='CPU:0')</span>
When using a parameter server it will assign them in a round-robin fashion.
When not using a parameter server it allows GPU:0 placement otherwise CPU:0.
Initialize VariableDeviceChooser.</p>
<h3>Args</h3>

<ul>
<li><strong>num_parameter_servers</strong>: number of parameter servers.</li>
<li><strong>ps_device</strong>: string representing the parameter server device.</li>
<li><strong>placement</strong>: string representing the placement of the variable either CPU:0
or GPU:0. When using parameter servers forced to CPU:0.</li>
</ul>
<hr />
<h1 id="valid-types-for-loss-variables-and-gradients">Valid types for loss, variables and gradients</h1>
<p><span class="extra_h1"><span style="color:black;"><a href=https://github.com/n3011/tefla/blob/master/tefla/utils/util.py#L205 target="_blank"><b>tefla.utils.util.valid_dtypes</b></a></span>  ()</span>
Subclasses should override to allow other float types.
<h3>Returns</h3></p>
<p>Valid types for loss, variables and gradients.</p>
<hr />
<h1 id="asserts-tensors-are-all-valid-types-see-_valid_dtypes">Asserts tensors are all valid types (see <code>_valid_dtypes</code>)</h1>
<p><span class="extra_h1"><span style="color:black;"><a href=https://github.com/n3011/tefla/blob/master/tefla/utils/util.py#L214 target="_blank"><b>tefla.utils.util.assert_valid_dtypes</b></a></span>  (tensors)</span>
<h3>Args</h3></p>
<ul>
<li>
<p><strong>tensors</strong>: Tensors to check.
<h3>Raises</h3></p>
</li>
<li>
<p><strong>ValueError</strong>: If any tensor is not a valid type.</p>
</li>
</ul>
<hr />
<h1 id="returns-value-if-value_or_tensor_or_var-has-a-constant-value">Returns value if value_or_tensor_or_var has a constant value</h1>
<p><span class="extra_h1"><span style="color:black;"><a href=https://github.com/n3011/tefla/blob/master/tefla/utils/util.py#L229 target="_blank"><b>tefla.utils.util.constant_value</b></a></span>  (value_or_tensor_or_var,  dtype=None)</span></p>
<h3>Args</h3>

<ul>
<li><strong>value_or_tensor_or_var</strong>: A value, a <code>Tensor</code> or a <code>Variable</code>.</li>
<li><strong>dtype</strong>: Optional <code>tf.dtype</code>, if set it would check it has the right</li>
<li>dtype.</li>
</ul>
<h3>Returns</h3>

<p>The constant value or None if it not constant.</p>
<hr />
<h1 id="return-either-fn1-or-fn2-based-on-the-boolean-value-of-pred">Return either fn1() or fn2() based on the boolean value of <code>pred</code></h1>
<p><span class="extra_h1"><span style="color:black;"><a href=https://github.com/n3011/tefla/blob/master/tefla/utils/util.py#L258 target="_blank"><b>tefla.utils.util.static_cond</b></a></span>  (pred,  fn1,  fn2)</span></p>
<p>Same signature as <code>control_flow_ops.cond()</code> but requires pred to be a bool.</p>
<h3>Args</h3>

<ul>
<li><strong>pred</strong>: A value determining whether to return the result of <code>fn1</code> or <code>fn2</code>.</li>
<li><strong>fn1</strong>: The callable to be performed if pred is true.</li>
<li><strong>fn2</strong>: The callable to be performed if pred is false.</li>
</ul>
<h3>Returns</h3>

<p>Tensors returned by the call to either <code>fn1</code> or <code>fn2</code>.</p>
<hr />
<h1 id="return-either-fn1-or-fn2-based-on-the-boolean-predicatevalue-pred">Return either fn1() or fn2() based on the boolean predicate/value <code>pred</code></h1>
<p><span class="extra_h1"><span style="color:black;"><a href=https://github.com/n3011/tefla/blob/master/tefla/utils/util.py#L284 target="_blank"><b>tefla.utils.util.smart_cond</b></a></span>  (pred,  fn1,  fn2,  name=None)</span></p>
<p>If <code>pred</code> is bool or has a constant value it would use <code>static_cond</code>,
 otherwise it would use <code>tf.cond</code>.</p>
<h3>Args</h3>

<ul>
<li><strong>pred</strong>: A scalar determining whether to return the result of <code>fn1</code> or <code>fn2</code>.</li>
<li><strong>fn1</strong>: The callable to be performed if pred is true.</li>
<li><strong>fn2</strong>: The callable to be performed if pred is false.</li>
<li>
<p><strong>name</strong>: Optional name prefix when using tf.cond
<h3>Returns</h3></p>
</li>
<li>
<p>Tensors returned by the call to either <code>fn1</code> or <code>fn2</code>.</p>
</li>
</ul>
<h3>Returns</h3>

<p>Tensors returned by the call to either <code>fn1</code> or <code>fn2</code>.</p>
<hr />
<h1 id="transform-numeric-labels-into-onehot_labels">Transform numeric labels into onehot_labels</h1>
<p><span class="extra_h1"><span style="color:black;"><a href=https://github.com/n3011/tefla/blob/master/tefla/utils/util.py#L336 target="_blank"><b>tefla.utils.util.one_hot</b></a></span>  (labels,  num_classes,  name='one_hot')</span>
<h3>Args</h3></p>
<ul>
<li><strong>labels</strong>: [batch_size] target labels.</li>
<li><strong>num_classes</strong>: total number of classes.</li>
<li>
<p><strong>scope</strong>: Optional scope for op_scope.
<h3>Returns</h3></p>
</li>
<li>
<p>one hot encoding of the labels.</p>
</li>
</ul>
<h3>Returns</h3>

<p>one hot encoding of the labels.</p>
<hr />
<h1 id="returns-a-true-if-its-input-is-a-collectionssequence-except-strings">Returns a true if its input is a collections.Sequence (except strings)</h1>
<p><span class="extra_h1"><span style="color:black;"><a href=https://github.com/n3011/tefla/blob/master/tefla/utils/util.py#L356 target="_blank"><b>tefla.utils.util.is_sequence</b></a></span>  (seq)</span></p>
<h3>Args</h3>

<ul>
<li><strong>seq</strong>: an input sequence.</li>
</ul>
<h3>Returns</h3>

<p>True if the sequence is a not a string and is a collections.Sequence.</p>
<hr />
<h1 id="returns-a-flat-sequence-from-a-given-nested-structure">Returns a flat sequence from a given nested structure</h1>
<p><span class="extra_h1"><span style="color:black;"><a href=https://github.com/n3011/tefla/blob/master/tefla/utils/util.py#L368 target="_blank"><b>tefla.utils.util.flatten_sq</b></a></span>  (nest_sq)</span>
If <code>nest</code> is not a sequence, this returns a single-element list: <code>[nest]</code>.</p>
<h3>Args</h3>

<ul>
<li><strong>nest</strong>: an arbitrarily nested structure or a scalar object.
Note, numpy arrays are considered scalars.</li>
</ul>
<h3>Returns</h3>

<p>A Python list, the flattened version of the input.</p>
<hr />
<h1 id="returns-the-last-dimension-of-shape-while-checking-it-has-min_rank">Returns the last dimension of shape while checking it has min_rank</h1>
<p><span class="extra_h1"><span style="color:black;"><a href=https://github.com/n3011/tefla/blob/master/tefla/utils/util.py#L420 target="_blank"><b>tefla.utils.util.last_dimension</b></a></span>  (shape,  min_rank=1)</span></p>
<h3>Args</h3>

<ul>
<li><strong>shape</strong>: A <code>TensorShape</code>.</li>
<li><strong>min_rank</strong>: Integer, minimum rank of shape.</li>
</ul>
<h3>Returns</h3>

<p>The value of the last dimension.</p>
<hr />
<h1 id="load-graph-from-frozen-weights-and-model">Load Graph from frozen weights and model</h1>
<p><span class="extra_h1"><span style="color:black;"><a href=https://github.com/n3011/tefla/blob/master/tefla/utils/util.py#L446 target="_blank"><b>tefla.utils.util.load_frozen_graph</b></a></span>  (frozen_graph)</span></p>
<h3>Args</h3>

<ul>
<li><strong>frozen_graph</strong>: binary pb file</li>
</ul>
<h3>Returns</h3>

<p>loaded graph</p>
<hr />
<h1 id="normalize-a-input-layer">Normalize a input layer</h1>
<p><span class="extra_h1"><span style="color:black;"><a href=https://github.com/n3011/tefla/blob/master/tefla/utils/util.py#L474 target="_blank"><b>tefla.utils.util.normalize</b></a></span>  (input_layer)</span></p>
<h3>Args</h3>

<ul>
<li><strong>inmput_layer</strong>: input layer tp normalize</li>
</ul>
<h3>Returns</h3>

<p>normalized layer</p>
<hr />
<h1 id="denormalize-a-input-layer">DeNormalize a input layer</h1>
<p><span class="extra_h1"><span style="color:black;"><a href=https://github.com/n3011/tefla/blob/master/tefla/utils/util.py#L486 target="_blank"><b>tefla.utils.util.denormalize</b></a></span>  (input_layer)</span></p>
<h3>Args</h3>

<ul>
<li><strong>input_layer</strong>: input layer to de normalize</li>
</ul>
<h3>Returns</h3>

<p>denormalized layer</p>
<hr />
<h1 id="computes-the-squared-pairwise-euclidean-distances-between-x-and-y">Computes the squared pairwise Euclidean distances between x and y</h1>
<p><span class="extra_h1"><span style="color:black;"><a href=https://github.com/n3011/tefla/blob/master/tefla/utils/util.py#L652 target="_blank"><b>tefla.utils.util.compute_pairwise_distances</b></a></span>  (x,  y)</span></p>
<h3>Args</h3>

<ul>
<li><strong>x</strong>: a tensor of shape [num_x_samples, num_features]</li>
<li><strong>y</strong>: a tensor of shape [num_y_samples, num_features]</li>
</ul>
<h3>Returns</h3>

<p>a distance matrix of dimensions [num_x_samples, num_y_samples].</p>
<hr />
<h1 id="computes-a-guassian-radial-basis-kernel-between-the-samples-of-x-and-y">Computes a Guassian Radial Basis Kernel between the samples of x and y</h1>
<p><span class="extra_h1"><span style="color:black;"><a href=https://github.com/n3011/tefla/blob/master/tefla/utils/util.py#L677 target="_blank"><b>tefla.utils.util.gaussian_kernel_matrix</b></a></span>  (x,  y,  sigmas)</span>
We create a sum of multiple gaussian kernels each having a width sigma_i.</p>
<h3>Args</h3>

<ul>
<li><strong>x</strong>: a tensor of shape [num_samples, num_features]</li>
<li><strong>y</strong>: a tensor of shape [num_samples, num_features]</li>
<li><strong>sigmas</strong>: a tensor of floats which denote the widths of each of the
gaussians in the kernel.</li>
</ul>
<h3>Returns</h3>

<p>A tensor of shape [num_samples{x}, num_samples{y}] with the RBF kernel.</p>
<hr />
<h1 id="compute-the-length-of-a-sequence-0-are-masked">compute the length of a sequence. 0 are masked</h1>
<p><span class="extra_h1"><span style="color:black;"><a href=https://github.com/n3011/tefla/blob/master/tefla/utils/util.py#L699 target="_blank"><b>tefla.utils.util.retrieve_seq_length</b></a></span>  (data)</span></p>
<h3>Args</h3>

<ul>
<li><strong>data</strong>: input sequence</li>
</ul>
<h3>Returns</h3>

<p>a <code>int</code>, length of the sequence</p>
<hr />
<h1 id="advanced-indexing-for-sequences">Advanced Indexing for Sequences</h1>
<p><span class="extra_h1"><span style="color:black;"><a href=https://github.com/n3011/tefla/blob/master/tefla/utils/util.py#L715 target="_blank"><b>tefla.utils.util.advanced_indexing</b></a></span>  (inp,  index)</span>
<h3>Args</h3></p>
<ul>
<li><strong>inp</strong>: input sequence</li>
<li><strong>index</strong>: input index for indexing</li>
</ul>
<h3>Returns</h3>

<p>a indexed sequence</p>
<hr />
<h1 id="pad_sequences">pad_sequences</h1>
<p><span class="extra_h1"><span style="color:black;"><a href=https://github.com/n3011/tefla/blob/master/tefla/utils/util.py#L733 target="_blank"><b>tefla.utils.util.pad_sequences</b></a></span>  (sequences,  maxlen=None,  dtype='int32',  padding='post',  truncating='post',  value=0.0)</span>
Pad each sequence to the same length: the length of the longest sequence.
If maxlen is provided, any sequence longer than maxlen is truncated to
maxlen. Truncation happens off either the beginning or the end (default)
of the sequence. Supports pre-padding and post-padding (default).</p>
<h3>Args</h3>

<ul>
<li><strong>sequences</strong>: list of lists where each element is a sequence.</li>
<li><strong>maxlen</strong>: a <code>int</code>, maximum length.</li>
<li><strong>dtype</strong>: type to cast the resulting sequence.</li>
<li><strong>padding</strong>: 'pre' or 'post', pad either before or after each sequence.</li>
<li><strong>truncating</strong>: 'pre' or 'post', remove values from sequences larger than
maxlen either in the beginning or in the end of the sequence</li>
<li><strong>value</strong>: <code>float</code>, value to pad the sequences to the desired value.</li>
</ul>
<h3>Returns</h3>

<h3>x</h3>

<p><code>numpy array</code> with dimensions (number_of_sequences, maxlen)</p>
<hr />
<h1 id="creates-a-dictionary-charinteger-for-each-unique-character">Creates a dictionary char:integer for each unique character</h1>
<p><span class="extra_h1"><span style="color:black;"><a href=https://github.com/n3011/tefla/blob/master/tefla/utils/util.py#L779 target="_blank"><b>tefla.utils.util.chars_to_dictionary</b></a></span>  (string)</span>
<h3>Args</h3></p>
<ul>
<li><strong>string</strong>: a <code>string</code> input</li>
</ul>
<h3>Returns</h3>

<p>dictionary of chars</p>
<hr />
<h1 id="string_to_semi_redundant_sequences">string_to_semi_redundant_sequences</h1>
<p><span class="extra_h1"><span style="color:black;"><a href=https://github.com/n3011/tefla/blob/master/tefla/utils/util.py#L792 target="_blank"><b>tefla.utils.util.string_to_semi_redundant_sequences</b></a></span>  (string,  seq_maxlen=25,  redun_step=3,  char_idx=None)</span>
Vectorize a string and returns parsed sequences and targets, along with
the associated dictionary.</p>
<h3>Args</h3>

<ul>
<li><strong>string</strong>: <code>str</code>. Lower-case text from input text file.</li>
<li><strong>seq_maxlen</strong>: <code>int</code>. Maximum length of a sequence. Default: 25.</li>
<li><strong>redun_step</strong>: <code>int</code>. Redundancy step. Default: 3.</li>
<li><strong>char_idx</strong>: 'dict'. A dictionary to convert chars to positions. Will be automatically generated if None</li>
</ul>
<h3>Returns</h3>

<p>A tuple: (inputs, targets, dictionary)</p>
<hr />
<h1 id="vectorize-text-file">Vectorize Text file</h1>
<p><span class="extra_h1"><span style="color:black;"><a href=https://github.com/n3011/tefla/blob/master/tefla/utils/util.py#L834 target="_blank"><b>tefla.utils.util.textfile_to_semi_redundant_sequences</b></a></span>  (path,  seq_maxlen=25,  redun_step=3,  to_lower_case=False,  pre_defined_char_idx=None)</span>
textfile_to_semi_redundant_sequences.
Vectorize a string from a textfile and returns parsed sequences and targets, along with
the associated dictionary.</p>
<h3>Args</h3>

<ul>
<li><strong>path</strong>: <code>str</code>. path of the input text file.</li>
<li><strong>seq_maxlen</strong>: <code>int</code>. Maximum length of a sequence. Default: 25.</li>
<li><strong>redun_step</strong>: <code>int</code>. Redundancy step. Default: 3.</li>
<li><strong>to_lower_case</strong>: a <code>bool</code>, if true, convert to lowercase</li>
<li><strong>pre_defined_char_idx</strong>: 'dict'. A dictionary to convert chars to positions. Will be automatically generated if None</li>
</ul>
<h3>Returns</h3>

<p>A tuple: (inputs, targets, dictionary)</p>
<hr />
<h1 id="computes-log-probabilities-using-numerically-stable-trick">Computes log probabilities using numerically stable trick</h1>
<p><span class="extra_h1"><span style="color:black;"><a href=https://github.com/n3011/tefla/blob/master/tefla/utils/util.py#L857 target="_blank"><b>tefla.utils.util.logits_to_log_prob</b></a></span>  (logits)</span>
This uses two numerical stability tricks:
1) softmax(x) = softmax(x - c) where c is a constant applied to all
arguments. If we set c = max(x) then the softmax is more numerically
stable.
2) log softmax(x) is not numerically stable, but we can stabilize it
by using the identity log softmax(x) = x - log sum exp(x)</p>
<h3>Args</h3>

<ul>
<li><strong>logits</strong>: Tensor of arbitrary shape whose last dimension contains logits.</li>
</ul>
<h3>Returns</h3>

<p>A tensor of the same shape as the input, but with corresponding log
probabilities.</p>
<hr />
<h1 id="get-the-name-of-the-op-that-created-a-tensor">Get the name of the op that created a tensor</h1>
<p><span class="extra_h1"><span style="color:black;"><a href=https://github.com/n3011/tefla/blob/master/tefla/utils/util.py#L887 target="_blank"><b>tefla.utils.util.GetTensorOpName</b></a></span>  (x)</span>
Useful for naming related tensors, as ':' in name field of op is not permitted</p>
<h3>Args</h3>

<p><h3>x</h3></p>
<p>the input tensor.</p>
<h3>Returns</h3>

<p>the name of the op.</p>
<hr />
<h1 id="returns-the-union-of-two-lists">Returns the union of two lists</h1>
<p><span class="extra_h1"><span style="color:black;"><a href=https://github.com/n3011/tefla/blob/master/tefla/utils/util.py#L905 target="_blank"><b>tefla.utils.util.ListUnion</b></a></span>  (list_1,  list_2)</span>
Python sets can have a non-deterministic iteration order. In some
contexts, this could lead to TensorFlow producing two different
programs when the same Python script is run twice. In these contexts
we use lists instead of sets.
This function is not designed to be especially fast and should only
be used with small lists.</p>
<h3>Args</h3>

<ul>
<li>list_1: A list</li>
<li>list_2: Another list</li>
</ul>
<h3>Returns</h3>

<p>A new list containing one copy of each unique element of list_1 and
  list_2. Uniqueness is determined by "x in union" logic; e.g. two
`  string of that value appearing in the union.</p>
<hr />
<h1 id="maps-xs-to-consumers">Maps xs to consumers</h1>
<p><span class="extra_h1"><span style="color:black;"><a href=https://github.com/n3011/tefla/blob/master/tefla/utils/util.py#L938 target="_blank"><b>tefla.utils.util.Interface</b></a></span>  (ys,  xs)</span>
  Returns a dict mapping each element of xs to any of its consumers that are
  indirectly consumed by ys.</p>
<h3>Args</h3>

<p>ys: The outputs
  xs: The inputs</p>
<h3>Returns</h3>

<p>out: Dict mapping each member x of <code>xs</code> to a list of all Tensors that are
   direct consumers of x and are eventually consumed by a member of
   <code>ys</code>.</p>
<hr />
<h1 id="clip-an-array-of-tensors-by-l2-norm">Clip an array of tensors by L2 norm</h1>
<p><span class="extra_h1"><span style="color:black;"><a href=https://github.com/n3011/tefla/blob/master/tefla/utils/util.py#L982 target="_blank"><b>tefla.utils.util.BatchClipByL2norm</b></a></span>  (t,  upper_bound,  name=None)</span>
Shrink each dimension-0 slice of tensor (for matrix it is each row) such
that the l2 norm is at most upper_bound. Here we clip each row as it
corresponds to each example in the batch.</p>
<h3>Args</h3>

<p>t: the input tensor.
  upper_bound: the upperbound of the L2 norm.
  name: optional name.</p>
<h3>Returns</h3>

<p>the clipped tensor.</p>
<hr />
<h1 id="add-iid-gaussian-noise-0-sigma2-to-every-entry-of-t">Add i.i.d. Gaussian noise (0, sigma^2) to every entry of t</h1>
<p><span class="extra_h1"><span style="color:black;"><a href=https://github.com/n3011/tefla/blob/master/tefla/utils/util.py#L1013 target="_blank"><b>tefla.utils.util.AddGaussianNoise</b></a></span>  (t,  sigma,  name=None)</span></p>
<h3>Args</h3>

<p>t: the input tensor.
  sigma: the stddev of the Gaussian noise.
  name: optional name.</p>
<h3>Returns</h3>

<p>the noisy tensor.</p>
<hr />
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../../license/" class="btn btn-neutral float-right" title="License">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../../dataset/reader/" class="btn btn-neutral" title="Reader"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
          <a href="https://github.com/n3011/tefla/" class="fa fa-github" style="float: left; color: #fcfcfc"> GitHub</a>
      
      
        <span><a href="../../dataset/reader/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../../license/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme.js" defer></script>
      <script src="../../search/main.js" defer></script>

</body>
</html>
